## AutoML vs. ручные модели — Kaggle Playground Series S5E11

Соревнование: [Kaggle — Playground Series S5E11](https://www.kaggle.com/competitions/playground-series-s5e11/overview).

### Описание задачи

- **Тип задачи**: бинарная классификация.
- **Цель**: предсказать вероятность возврата займа — таргет `loan_paid_back`.
- **Метрика соревнования**: **ROC-AUC** (чем выше, тем лучше).
- **Данные**:
  - Train: **593,994** строк, **13** колонок (включая `id` и `loan_paid_back`)
  - Test: **254,569** строк, **12** колонок (без таргета)

### Постановка (моя цель в работе)

По заданию нужно было:
- либо **побить AutoML-решение** собственной моделью,
- либо, если не получится, **попробовать минимум 3 разных подхода**.

Все эксперименты, код, фичи и сохранённые сабмиты лежат в `AutoML.ipynb`.

### Что сделано в ноутбуке `AutoML.ipynb`

- **EDA**: проверка типов/пропусков, распределений, выбросов, ключевые инсайты по категориальным признакам.
- **Feature Engineering (11 → 69 признаков)**:
  - извлечение `grade_letter` / `grade_digit` из `grade_subgrade`
  - числовые взаимодействия (ratio/произведения, оценка нагрузки платежа)
  - групповые статистики по `employment_status`, `grade_subgrade`, `loan_purpose`, `education_level`
  - кросс-фичи (комбинации категорий)
  - пороговые флаги (high/low credit, income, debt, loan, interest)
- **Модели**:
  - **LightAutoML** - 2 конфигурации
  - **CatBoost (GPU) + Optuna** (подбор гиперпараметров + CV)
  - **Стэкинг CatBoost + LightGBM**
  - **LightGBM** (label encoding категорий + 3-fold CV)

### Результаты (leaderboard)

Ниже — зафиксированные значения из ноутбука:

| Подход | Public Score | Private Score |
|---|---:|---:|
| **LightAutoML (baseline)** | **0.92477** | **0.92584** |
| CatBoost + Optuna | 0.92087 | 0.92156 |
| CatBoost + LightGBM (stacking) | 0.92163 | 0.92079 |
| LightGBM | 0.91943 | 0.91998 |

**Итог**: AutoML baseline оказался сильнее моих ручных решений на этом датасете

![Результаты stacking](refs/final_metric_stacking.png)

### Как воспроизвести

1. Скачайте данные соревнования и положите рядом с ноутбуком:
   - `train.csv`
   - `test.csv`
2. Откройте и выполните `AutoML.ipynb` (локально или в Kaggle).
3. На выходе будут сохранены файлы сабмита (см. таблицу выше).

### Структура репозитория

- `AutoML.ipynb` — весь пайплайн: EDA - FE - обучение моделей - сабмиты.
- `README.md` — краткое описание задачи и результатов.
